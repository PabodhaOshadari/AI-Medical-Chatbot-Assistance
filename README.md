# AI-Medical-Chatbot-Assistance

âœ¨ Features
ğŸ” Contextual document retrieval using Pinecone
ğŸ§¬ Semantic search via Hugging Face sentence transformers
ğŸ¤– Intelligent responses using OpenAI's GPT-4o-mini
ğŸ“„ Medical knowledge ingestion from PDF documents
ğŸŒ Web-based chat interface built with Flask
ğŸ” Secure API key handling with `.env`


ğŸ“š Data Source
The chatbot uses data extracted from the following resource:
ğŸ“˜ The Gale Encyclopedia of Medicine â€“ Second Edition
Documents are processed, split into chunks, and embedded for efficient vector-based retrieval.


ğŸ› ï¸ Tech Stack
Python 3.x
Flask
LangChain
Hugging Face Transformers
Pinecone
OpenAI GPT (gpt-4o-mini)
dotenv


ğŸ“ Project Structure
.
â”œâ”€â”€ app.py                     # Flask server and chatbot logic
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ helper.py              # PDF loader, text splitter, embedding setup
â”‚   â””â”€â”€ prompt.py              # System prompt for chatbot
â”œâ”€â”€ Data/                      # Directory for medical PDFs
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ chat.html              # Web interface
â”œâ”€â”€ .env                       # Environment file with API keys
â””â”€â”€ README.md                  # Project documentation


âš™ï¸ Setup Instructions
1. Clone the Repository
   git clone https://github.com/yourusername/ai-medical-chatbot.git
   cd ai-medical-chatbot

2. Install Dependencies
   pip install -r requirements.txt

3. Configure Environment Variables
   Create a .env file with your keys:
   OPENAI_API_KEY=your_openai_api_key
   PINECONE_API_KEY=your_pinecone_api_key

4. Add PDF Files
   Put your medical PDF files (like the Gale Encyclopedia) inside the Data/ folder.

5. Create or Update Vector Store
   python src/create_vector_store.py

6. Start the Flask Web App
   python app.py
   
